{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3. Connectionist neuropsychology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 / QGM : 파트 3 - 연결주의모형 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* INTRODUCTION\n",
    "* COGNITIVE NEUROPSYCHOLOGY\n",
    "* NEURAL NETWORK MODELS\n",
    "* LEARNING AND LESIONING SIMULATIONS\n",
    "* AVOIDING SMALL-SCALE ARTEFACTS\n",
    "* PLAUT’S DOUBLE DISSOCIATION WITHOUT MODULARITY\n",
    "* REGULARITY AND FREQUENCY CONFOUNDS\n",
    "* CONNECTIONIST DOUBLE DISSOCIATION\n",
    "* CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "\"If your TV set suddenly loses the color you can conclude that picture transmission and color information must be separate processes (single dissociation: they cannot be independent because you cannot lose the picture and still have the color). If on the other hand you have two TV sets, one without sound and one without a picture you can conclude that these must be two independent functions (double dissociation).\"\n",
    "* [2] 나무위키:신경과학-이중해리 - https://namu.wiki/w/%EC%8B%A0%EA%B2%BD%EA%B3%BC%ED%95%99#fn-8\n",
    "* Cognitive neuroscience lecture 5 - http://contents.kocw.net/KOCW/document/2015/chosun/seoeunhyun/5.pdf\n",
    "* [3] Cognitive Neuropsychology Methods - http://www.powershow.com/view/12a9a1-MzA2Y/Cognitive_Neuropsychology_Methods_powerpoint_ppt_presentation\n",
    "* [4] Methods in Cognitive Neuroscience I - http://www.slideshare.net/dominic54/methods-in-cognitive-neuroscience-i\n",
    "* [5] Cognitive Neuroscience - Current Perspectives And Approaches - http://www.slideshare.net/iVivekMisra/cognitive-neuroscience-current-perspectives-and-approaches\n",
    "* [6] Dissociation (neuropsychology) - https://en.wikipedia.org/wiki/Dissociation_(neuropsychology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field of cognitive neuropsychology employs the patterns of performance observed in brain-damaged patients to constrain our models of normal cognitive function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cognitive neuropsychology\n",
    "* “box and arrow” models\n",
    "    - This methodology was historically based upon simple “box and arrow” models, with particular cognitive deficits being taken as indicative of the selective breakdown of corresponding “boxes” or “arrows”.\n",
    "* <font color=\"red\">double dissociation</font>\n",
    "    - The concept of double dis- sociation has been of particular importance for this enterprise, with its pres- ence being taken to imply modularity across a whole range of systems.\n",
    "* Cognitive modelling\n",
    "    - Cognitive modelling has now moved on, and the use of connectionist techniques to provide detailed models of the inner workings of these modules or “boxes” is becoming increasingly common.\n",
    "    - These individual network models can then be wired together in the manner of the old box and arrow models, and all the old explanations of patient data can carry through.\n",
    "* dyslexia-like effect\n",
    "    - In particular, Bullinaria & Chater (1995) have considered the possibility that double dissociation does not really imply modularity, but may also be possible as a result of damage to fully distributed connectionist systems. \n",
    "    - These general arguments have since been extended from simple abstract mappings through to more realistic single route models of reading, which show how surface dyslexia-like effects can arise but phonological dyslexia effects cannot (Bullinaria, 1994, 1997a,b). \n",
    "* modularity & counter-example\n",
    "    - Whilst finding a counter-example to the inference from double dissoci- ation to modularity would clearly settle the matter, failing to find a counter- example will always be less conclusive.\n",
    "    - Naturally, these apparent contradictions have caused a certain amount of confusion, particularly amongst researchers unfamiliar with the detailed workings of connectionist models. In this chapter I shall review and extend the work of Bullinaria & Chater (1995) with a view to minimizing future confusion in this area.\n",
    "* fully-connected feed-forward network\n",
    "* “consistency” VS “regularity\"\n",
    "    - In terms of network learning, a very high-frequency “irregular” item might be deemed more “regular” than a consistent set of regular items whose total frequency is still much less than the irregular item. \n",
    "* resource artefacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this chapter, I shall begin by reviewing the important relevant ideas from cognitive neuropsychology: \n",
    "* the traditional inference <font color=\"red\">from double dissociation to modularity</font>, \n",
    "* the <font color=\"red\">types of system that may exhibit double dissociation</font>, and \n",
    "* the problem of <font color=\"red\">resource artefacts</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGNITIVE NEUROPSYCHOLOGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dissociation\n",
    "* single dissociation\n",
    "* double dissociation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Any observed double dissociation (DD) of performance has a natural explanation in terms of the existence of separate modules</font> associated with the two tasks, with the two patients suffering damage to a different one of them.\n",
    "* A classic and well-known example occurs in the field of acquired reading problems. \n",
    "    - Extreme cases of surface dyslexia include patient KT, who could read 100% of nonwords and regular words but could only manage 47% of irregular words (McCarthy & Warrington, 1986). \n",
    "    - Conversely, the phono- logical dyslexic patient WB could read 90% of real words but was unable to read even the simplest of nonwords (Funnell, 1983)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### connectionist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bule\">However, the modules do not necessarily have to operate in parallel</font> like this—the same data could be taken to imply modules that operate in series (e.g. by Patterson & Marcel, 1992; Bullinaria, 1997b). \n",
    "* In fact there could be any number of different modular accounts for a particular DD, and \n",
    "    - the account that appears <font color=\"red\">most natural</font> \n",
    "        - from the point of <font color=\"red\">view of boxes and arrows</font> \n",
    "    - might <font color=\"blue\">not look so natural</font> \n",
    "        - from the point of <font color=\"blue\">view of connectionist systems</font>. \n",
    "* For our reading example, \n",
    "    - a rule-based box that can not deal with exception words seems less natural when it becomes clear that a neural network trained on all words will automatically learn to process the exception words as well as the regular words (Seidenberg & McClelland, 1989), \n",
    "    - and on damage result in surface dyslexia-type deficits, right down to the details of the regularization errors (Bullinaria, 1994, 1997a; Plaut, McClelland, Seidenberg, & Patterson, 1996). \n",
    "    - Furthermore, proficient reading using only a lexical/semantic route begins to look increasingly unnatural when we find that a neural network, trained to map between orthography, phonology, and semantics, prefers to access semantics from orthography via phonology, rather than by direct activation (Bullinaria, 1997b). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall not delve into the details here, but other areas in which DD has been observed and taken to infer mental structure include: \n",
    "* regular vs. irregular past tense production \n",
    "* lexical vs. syntactic components of number processing\n",
    "* aspects of visual processing\n",
    "* long-term vs. short-term memory \n",
    "* episodic vs. semantic memory\n",
    "* natural kinds vs. artefacts in picture naming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some early neural network models (Sartori, 1988; Wood, 1978) also seemed to indicate that DD was even possible in distributed systems, but these were very small scale models and the effects have since been seen to be largely the consequence of individual neurons acting as “modules” in their own right. \n",
    "* This led Shallice (1988, p. 257) to believe that “as yet there is no suggestion that a strong double dissociation can take place from two lesions within a properly distributed network”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resource artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As illustrated in Figures 3.2 and 3.3, a DD with a crossover in terms of patient performance, but not in task performance, can be explained as a <font color=\"red\">resource artefact</font> in a single system. \n",
    "* All that is required is for the <font color=\"blue\">two tasks to depend on a single resource in different manners, such that which task is performed better depends on the amount of resource that has been spared by the damage</font>. \n",
    "* Clearly, such a pattern of dissociation should NOT be taken to imply modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This section provides a <font color=\"red\">review of the relevant features common to most neural network models</font> used in cognitive psychology.\n",
    "* This will prepare us for the later sections in which we discuss some explicit simulations that have been formulated to elucidate the properties that form the <font color=\"red\">basis of connectionist neuropsychology</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to train the network, we specify a suitable error function E to minimize and iteratively update the weights wij (now including the biases) to reduce this error using gradient descent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.5.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically for this we use either the sum-squared output error measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, for classification problems with binary outputs, the cross-entropy error measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is also appropriate to add some form of regularization term to the gradient descent cost function to smooth the outputs or improve the generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading model example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고\n",
    "* [7] Word Recognition Models - http://www.slideshare.net/lrizoli/word-recognition-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/James_Mcclelland/publication/271590024/figure/fig4/AS:272621996605493@1442009557980/Figure-5-The-Seidenberg-and-McClelland's26-model-of-reading-Portions-in-black-depict.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cnbc.cmu.edu/~plaut/images/PMSP-sml.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to begin by illustrating this with a concrete example originally presented by Seidenberg & McClelland (1989) for their reading model, but using data from my own reading model (Bullinaria, 1997a).\n",
    "* In both cases we have a neural network model mapping from a simplified representation of orthography to a simplified representation of phonology via one hidden layer.\n",
    "* Figure 3.4 shows how the output performance on the regular word “tint” varies as the result of further training of a partially trained network.\n",
    "    - <font color=\"red\">tint <- regular word</font>\n",
    "    - wint <- regular nonword \n",
    "    - dint <- regular word \n",
    "    - pint <- irregular word\n",
    "    - comb <- control word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this simple example, we can easily see what will happen in the general case. Amongst other things, it follows straightforwardly from adding up the network weight change contributions due to individual training patterns that:\n",
    "1. High-frequency items are learnt more quickly than low-frequency items, because the appropriate weight changes are applied more often.\n",
    "2. Regular items will be learnt more quickly than irregular items, because consistent weight changes combine and inconsistent weight changes\n",
    "cancel.\n",
    "3. Ceiling effects will arise as the training items are mastered, because the\n",
    "sigmoids saturate and the weight changes tend to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING AND LESIONING SIMULATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we shall explore in some detail the relation between the basic learning and lesioning effects that arise automatically in the class of neural networks outlined above. \n",
    "* Fortunately, it proves feasible to do this by simulating some fairly small networks that are required to perform some rather <font color=\"red\">simple sets of regular and irregular mappings of varying frequency</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider first a simple fully-connected feedforward network \n",
    "* with 10 input units, \n",
    "* 100 hidden units and \n",
    "* 10 output units, \n",
    "    - with binary inputs and output targets \n",
    "    - trained on \n",
    "        - two sets of 100 regular items (permuted identity mappings) and\n",
    "        - two sets of 10 irregular items (random mappings). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted regularity and frequency effects were found, \n",
    "* as can be seen clearly in Figure 3.5 \n",
    "* which shows how the mean output $Sum_{i}(P)$’s develop during training \n",
    "* for each of the four item types \n",
    "    - high-frequency regular, \n",
    "    - low- frequency regular, \n",
    "    - high-frequency irregular, \n",
    "    - low-frequency irregular\n",
    "* and two target activations (0, 1). \n",
    "* If we set a particular correct response threshold for the Sumi(P)’s, e.g. ± 2.2 corresponding to output activations less than 0.1 for targets of 0 and greater than 0.9 for targets of 1, \n",
    "* we see that the more regular and higher-frequency items are the first to be learned during training and end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add a regularization term to the gradient descent error function that leads to weight decay during training, the $Sum_{i}(P)$’s eventually level off rather than increasing indefinitely, as in Figure 3.5, but we still get the same clear item-type dependence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now turn to the consequences of lesioning these networks. \n",
    "* Bullinaria & Chater (1995) found that damaging trained networks by removing random hidden units, removing random connections, globally scaling the weights, or adding random noise to the weights, all led to very similar patterns of results. \n",
    "* Figure 3.6 shows the effect of removing increasingly large numbers of connections from our network—we see that we get the reverse of the pattern of learning seen in Figure 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After brain damage, patients often (but not always) show a rapid improvement in performance (Geshwind, 1985). This is important to connectionist modellers for two reasons. \n",
    "* First, if relearning occurs automatically and quickly in patients, then we need to be sure that the same effects are observed in our models and that we are comparing patient and model data at equivalent stages of the relearning process. \n",
    "* Second, our models may be of assistance in formulating appropriate remedial strategies for brain-damaged patients (Plaut, 1996; Wilson & Patterson, 1990)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVOIDING SMALL-SCALE ARTEFACTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The damage curves of Figure 3.6 are relatively smooth because we have averaged over many output units and many training items, and because our network has many more hidden units and connections than are actually required to perform the given mappings. \n",
    "* For smaller networks, however, the effect of individual damage contributions can be large enough to produce wildly fluctuating performance on individual items, which in turn can result in dissociations in arbitrary directions. <font color=\"red\">Often these small-scale artefacts are sufficient to produce convincing-looking double dissociations</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### graceful degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the lost contribution is small compared to the corresponding total, i.e. \n",
    "    - the ratio C = $c_{ij}/(Σ_{k}c_{ik})$ \n",
    "    - is much less than one, then the output activation will not be changed much and it will take many such lost contributions to result in an output change large enough to be deemed an error. \n",
    "* This is the brain-like resilience to damage often known as graceful degradation. \n",
    "* Fortunately, this distribution of information processing tends to occur automatically, simply by supplying the network with a sufficiently large number of hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Figure 3.7 shows the distribution of 10,000 typical individual contribution ratios C for the high-frequency regular outputs in networks with 30 and 100 hidden units trained on the quasi-regular mapping discussed above</font>. For 100 hidden units, there are very few contributions with ratios C larger than one, but with only 30 hidden units, many contributions are much greater than their corresponding total and their removal will result in wild fluctuations in the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction in the number of large contribution ratios as we increase the number of hidden units is shown in Figure 3.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what can be done if limited computational resources render the use of sufficiently large numbers of hidden units impossible?\n",
    "* Well, consider the effect of network damage on the histograms in Figure 3.7. Obviously, after removing a random subset of the hidden units or connections, <font color=\"red\">the number of contributions will be reduced by some factor $α$</font>.\n",
    "* However, in large fully distributed networks, the mean contribution will not change much, and so the total contribution after damage is simply reduced to $αSum_{i}(P) = α Σw_{ij}Prev_{j}(P)$. \n",
    "* Note that we can achieve exactly the same result by simply globally scaling all the weights wij by the same factor $α$. \n",
    "* In smaller networks, of course, this equivalence breaks down because the means tend to suffer relatively large random fluctuations during damage.\n",
    "* However, since global weight scaling does not suffer from such random fluctuations, it can be used to simulate a smoothed form of lesioning and give a reasonable approximation in small networks to what will happen in more realistic networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAUT’S DOUBLE DISSOCIATION WITHOUT MODULARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] Cognitive Neuroscience of Language: 10: Deep dyslexia - http://www.inf.ed.ac.uk/teaching/courses/cnl/CNL_08_10_deep_dyslexia.pdf\n",
    "* [9] Chapter 8 Recurrent Backpropagation: Attractor network models of semantic and lexical processing - https://web.stanford.edu/group/pdplab/pdphandbook/handbookch9.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/dyslexia.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://web.stanford.edu/group/pdplab/pdphandbook/damaged_attractor.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plaut’s well-known paper entitled “Double dissociation without modularity: Evidence from connectionist neuropsychology” (Plaut, 1995)\n",
    "* His work was based on the models of deep dyslexia of Plaut & Shallice (1993), which in turn were extensions of the earlier models of Hinton & Shallice (1991). Deep dyslexia is a well-known acquired reading disorder characterized by semantic errors, such as reading “forest” as “tree”.\n",
    "* Of particular relevance to us are two patients who provide a DD between abstract and concrete word reading. Patient CAV was able to read correctly 55% of abstract words but only 36% of concrete words (Warrington, 1981), whereas patient PW could read 67% of concrete words but only 13% of abstract words (Patterson & Marcel, 1977)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Plaut (1995) himself points out, one of the problems when discussing \n",
    "* “modularity” is that different authors use different definitions of the term. \n",
    "    - A Fodor (1983) module, for example, is hard-wired, innate and informationally encapsulated,\n",
    "    - whereas a Coltheart (1985) module is defined to have none of those properties. \n",
    "* Moreover, the definitions provided are often imprecise, and sometimes they are even left totally implicit. \n",
    "* A cynic, such as myself, might therefore suggest that the situation would be less confusing if we all confined ourselves to describing our models and their ability to account for the neuro-psychological data, and made a conscious effort to avoid using words like “module” altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGULARITY AND FREQUENCY CONFOUNDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### past tense model of Marchman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another connectionist model that appears to be in even more direct conflict with the above discussion is the past tense model of Marchman (1993). \n",
    "* She used back-propagation to train a feedforward network to map from \n",
    "    - 45 input units representing the stem phonology, \n",
    "    - to 60 output units representing the corresponding past tense phonology, \n",
    "    - via 45 hidden units.\n",
    "* In contradiction to all our previous arguments, \n",
    "    - she concluded that \n",
    "        - “the acquisition of regular verbs became increasingly susceptible to injury, \n",
    "        - while the irregulars were learned quickly and were relatively impervious to damage”. \n",
    "* So what is at the root of this opposite conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECTIONIST DOUBLE DISSOCIATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] Connectionist Models in Cognitive Psycholgy - http://www.amazon.com/Connectionist-Cognitive-Psychology-Studies-Cognition/dp/0415646901/\n",
    "* [2] 나무위키:신경과학-이중해리 - https://namu.wiki/w/%EC%8B%A0%EA%B2%BD%EA%B3%BC%ED%95%99#fn-8\n",
    "* Cognitive neuroscience lecture 5 - http://contents.kocw.net/KOCW/document/2015/chosun/seoeunhyun/5.pdf\n",
    "* [3] Cognitive Neuropsychology Methods - http://www.powershow.com/view/12a9a1-MzA2Y/Cognitive_Neuropsychology_Methods_powerpoint_ppt_presentation\n",
    "* [4] Methods in Cognitive Neuroscience I - http://www.slideshare.net/dominic54/methods-in-cognitive-neuroscience-i\n",
    "* [5] Cognitive Neuroscience - Current Perspectives And Approaches - http://www.slideshare.net/iVivekMisra/cognitive-neuroscience-current-perspectives-and-approaches\n",
    "* [6] Dissociation (neuropsychology) - https://en.wikipedia.org/wiki/Dissociation_(neuropsychology)\n",
    "* [7] Word Recognition Models - http://www.slideshare.net/lrizoli/word-recognition-models\n",
    "* [8] Cognitive Neuroscience of Language: 10: Deep dyslexia - http://www.inf.ed.ac.uk/teaching/courses/cnl/CNL_08_10_deep_dyslexia.pdf\n",
    "* [9] Chapter 8 Recurrent Backpropagation: Attractor network models of semantic and lexical processing - https://web.stanford.edu/group/pdplab/pdphandbook/handbookch9.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
