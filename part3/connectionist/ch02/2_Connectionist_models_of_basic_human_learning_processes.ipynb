{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connectionist models of basic human learning processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 / QGM : 파트 3 - 연결주의모형 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* LINEAR AND NONLINEAR CLASSIFICATIONS\n",
    "* UNIQUE CUES\n",
    "* CHALLENGING UNIQUE CUE MODELS\n",
    "* BACK-PROPAGATION MODELS\n",
    "* CONFIGURAL MODELS\n",
    "* REPRESENTATIONAL FLEXIBILITY\n",
    "* ROLE OF THE HIPPOCAMPUS IN STIMULUS CODING\n",
    "* CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is natural to believe that the current high level of interest in connectionist models of cognitive processes is attributable to the impressive accounts such models can provide of human competencies (e.g. reading, classification, skill acquisition) and that the (arguable) improvement such models provide in explanatory power over nonconnectionist models is the main impetus to their growing acceptance amongst cognitive psychologists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter I discuss elementary learning processes in various human analogues of animal conditioning procedures and use the findings to draw conclusions about the basic properties required in realistic connectionist models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-level cognitive processes & Animal Pavlovian conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://2012books.lardbucket.org/books/beginning-psychology/section_11/72ff70c6cb32a57995de5d2081132da7.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In fact, there is a remarkable degree of similarity between the principles governing Pavlovian conditioning and human associative learning (Shanks, 1995) and there seems little risk at present that theories of human and animal learning will diverge seriously. \n",
    "* A second reason is more to do with persuasiveness: No matter how compelling the evidence is in Pavlovian conditioning for the involvement of connectionistic processes, there will always be a leap of faith involved in seeing a relationship between such processes and more high-level human abilities.\n",
    "* Studies of human associative processes provide an indispensable bridge spanning these two extreme fields, especially if high-level cognitive processes (e.g. causal induction) can be shown to obey the same rules as conditioning (Dickinson, 2001; Lober & Shanks, 2000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Very many of the so-called “supervised” networks and architectures that have been most extensively studied in the last few years take as their input a pattern of activation across a set of input units, generate an output pattern across a set of output units, and then receive some sort of signal from the outside world, indicating what the output pattern generated by the system should have been.\n",
    "* This sort of simple situation provides a straightforward model for\n",
    "    - associative learning and \n",
    "    - memory tasks, which conform to this input–output mapping description. \n",
    "* Some examples include \n",
    "    - generating the past tense of a verb from its stem, \n",
    "    - generating the pronunciation of a word from its written form, and\n",
    "    - deciding the category to which an object belongs.\n",
    "* These competences are complex, however, in a number of ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpler situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In consequence, it is necessary to turn to much simpler situations in which the learning task is stripped down to its bare essentials in such a way that the coding scheme, learning algorithm, and so on can be more directly and independently studied.\n",
    "* Participants are instructed to imagine that they are food allergists attempting to work out which foods various fictitious patients are allergic to. \n",
    "    - On each trial a meal is presented to the patient, comprising one or a small number of foods, and the participant has to predict whether an allergy ensues. \n",
    "    - Then feedback is given about the actual outcome and the participant goes on to the next trial. \n",
    "    - Over a series of trials (usually in the order of 50–200), various trial types are presented repeatedly in an intermixed order until the participant is correctly predicting the outcome on each trial. \n",
    "    - Finally, a transfer test is given to assess some aspect of the learning process. \n",
    "    - The parallel to Pavlovian conditioning should be clear, with the foods playing the role of conditioned stimuli (CSs) and the allergy the role of the unconditioned stimulus (US).\n",
    "* As we will see, despite the simplicity of the ability we are attempting to simulate, there are profound difficulties in creating an adequate connectionist theory, but a good deal of progress has nevertheless been made. \n",
    "* Also, it should be mentioned that the experimental designs on which this chapter focuses can generally be solved without the need for selective attention, and the models I review do not incorporate attentional processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR AND NONLINEAR CLASSIFICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feedforward networks or pattern associators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On every trial, some item consisting of a set of cues is presented. We calculate the activation $a_{o}$ of each output unit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the “error”, $d_{o}$, on the output unit between the obtained output, $a_{o}$, and the desired output, $t_{o}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the well-known “delta” rule (Stone, 1986) to change each of the weights in proportion to the error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elemental coding assumption & Rescorla–Wagner theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] Behavior Models - http://www.slideshare.net/zennboy/class-feb-15\n",
    "* [3] 레스콜라-와그너 모델(위키피디아) -  https://ko.wikipedia.org/wiki/%EA%B3%A0%EC%A0%84%EC%A0%81_%EC%A1%B0%EA%B1%B4%ED%99%94%EC%9D%98_%ED%96%89%EB%8F%99%EC%A0%81_%EC%97%B0%EA%B5%AC#.EB.A0.88.EC.8A.A4.EC.BD.9C.EB.9D.BC-.EC.99.80.EA.B7.B8.EB.84.88_.EB.AA.A8.EB.8D.B8\n",
    "* [4] 레스콜라-바그너 모델(블로그) - http://m.blog.naver.com/khrireg/10187749924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pattern associators, associative knowledge is represented in weighted\n",
    "connections between elements of the stimulus and elements of the outcome. The model given in equations (1)–(3) is in fact formally equivalent to the well-known Rescorla–Wagner theory (Rescorla & Wagner, 1972) of animal Pavlovian conditioning, a theory that has dominated conditioning research for nearly 30 years (Hall, 1991; Miller, Barnet, & Grahame, 1995) and which has many proven empirical successes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">While this learning algorithm has been successfully applied to many tasks, however, there is evidence to suggest that its “elemental” representational assumption is inadequate.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In learning to associate one pattern with another, for instance, it appears that in addition to learning direct associations between the outcome and the separate elements that make up the stimulus, higher-order representations of the stimulus can also be involved in associations with the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The inadequacy of the notion that the elements of the cue are directly and independently associated with the outcome comes from a number of sources.</font>\n",
    "\n",
    "* According to the elemental coding assumption, a compound cue such as ABC, comprising three elements, should elicit a response that is proportional to the sum of the weights of the elements A, B, and C. If these elements have previously been separately paired with a US and have each acquired asymptotic weights of 1.0, then the compound ABC should evoke summation, that is to say, a level of responding that is far higher than that elicited by the elements themselves.\n",
    "* <font color=\"blue\">Although the precise conditions remain to be clarified , there is now convincing evidence against this prediction from studies that reveal no evidence of summation in experiments of this sort</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonlinearly separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.massey.ac.nz/~mjjohnso/notes/59302/xor_plot.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another and more well-established source of evidence comes from the fact that humans can learn nonlinearly separable classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In single-layer networks, consider a network consisting of two input units (denoted x and y) connected to one output unit, where the inputs and correct output, to, can take on values between 0.0 and 1.0, and where the network is trained to classify input patterns into one of two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.4.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It follows that the only types of classification such a system can learn are linearly separable ones in which the members of the two categories can be distinguished by a simple linear boundary. \n",
    "* Specifically, <font color=\"blue\">for the delta rule model to learn a discrimination, it must be possible to construct a straight line in the x,y input space</font> that exactly divides the stimuli into the correct categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">However, people have no difficulty learning nonlinearly separable discriminations that the delta rule model would be unable to master.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following simple experiment. \n",
    "* In this task, \n",
    "    - 16 participants (UCL students) \n",
    "    - had to learn relationships \n",
    "    - between \n",
    "        - foods people ate and \n",
    "        - allergic reactions caused by those foods. \n",
    "* On each trial, \n",
    "    - a list of foods was described that the person had eaten, and \n",
    "    - the participant had to choose one out of a selection of possible allergies that the person suffered. \n",
    "        - The foods were such things as \n",
    "            - bananas, \n",
    "            - avocados, \n",
    "            - etc., and \n",
    "        - the allergies were called \n",
    "            - Type 1, \n",
    "            - Type 2, \n",
    "            - etc. \n",
    "    - Some of the people suffered no allergic reaction. \n",
    "    - After making their predictions, participants received feedback telling them the correct outcome for that trial. \n",
    "* Embedded in the design were critical trials of the following sorts which conform to a feature-neutral discrimination (Rudy & Sutherland, 1995): \n",
    "    - A → O, \n",
    "    - BC → O, \n",
    "    - C → no O, and \n",
    "    - AB → no O, \n",
    "        - where A–C are different foods, \n",
    "        - O is an allergy, and \n",
    "        - no O is no allergy. \n",
    "* Participants received 10 trials of each of these types in a fully randomized and intermixed fashion. \n",
    "* In fact, the full design included \n",
    "    - three distinct sets of trials conforming to this design; \n",
    "    - we have collapsed the data across these three sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examination of the trial types reveals that the discrimination is not lin- early separable. Each of the elements (A, B, C) is equally often paired with the outcome and with no outcome, so the discrimination cannot be solved on the basis of summation of the weights of individual stimulus elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A moment’s thought reveals that a pattern associator like that in Fig. 2.1 cannot solve the discrimination, so the key question is, can people? The answer is “yes”, as Fig. 2.2 shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph then plots the means of these scores transformed into percentages. With this scoring scheme, the chance level is 25% for trials associated with an allergy and 75% for trials associated with no allergy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">This is a result that single-layer pattern associators governed by the delta rule is unable to explain.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIQUE CUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as it has been recognized for many years that humans can solve such learning problems(=nonlinearity), so a simple account of how this is achieved has long been available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unique elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wagner and Rescorla (1972) suggested that whenever two elements occur together, their combination gives rise to further “unique” elements which function much like the elements themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unique cue model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In network terms, unique cue theories are easy to implement. As elaborated by Gluck (1991), the idea would be to supplement the layer of input units with additional units that correspond to the unique cues.\n",
    "* Thus, in addition to input units for elements A and B, there would be an AB unit which would only be activated when both A and B are present.\n",
    "* What about higher-order configurations? ABC?\n",
    "    - One extreme possibility is that the network should contain seven input units (three for the elements, one each for con- figurations AB, AC, and BC, and one for configuration ABC) corresponding to the complete power set of elements.\n",
    "    - An alternative, therefore, is to constrain the <font color=\"red\">unique cue units to consist of just the element-pairs AB, AC, and BC.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be plain that the results of the experiment shown in Fig. 2.2 are readily accounted for by a unique cue analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the \n",
    "    - A → O, \n",
    "    - BC → O, \n",
    "    - C → no O, \n",
    "    - AB → no O \n",
    "    - feature-neutral problem, \n",
    "        - none of the elements can become a reliable predictor of the category, \n",
    "        - but the unique cues can. \n",
    "* When unique cues are included, the trial types become \n",
    "    - A → O, \n",
    "    - BCX → O, \n",
    "    - C → no O, and \n",
    "    - ABY → no O, \n",
    "        - where X is the unique cue \n",
    "            - created by the combination of elements B and C and \n",
    "        - Y is the unique cue \n",
    "            - created by the combination of A and B. \n",
    "    - It is simple to see that the discrimination is solved if \n",
    "        - cue A and the unique cue X acquire positive weights for the category, \n",
    "        - B and C have weights of zero, and \n",
    "        - Y has a negative weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHALLENGING UNIQUE CUE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the obvious predictive successes of unique cue models, it is fairly easy to show that the patterns of generalization predicted by <font color=\"red\">such networks are inappropriate</font>, and we can illustrate this with an experiment by Shanks, Charles, Darby, and Azmi (1998a, Experiment 3) which uses a design originally adopted in animal conditioning studies by Pearce and Wilson (1991; Wilson & Pearce, 1992). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The basic idea is that \n",
    "    - participants learn \n",
    "        - an A → O, \n",
    "        - AB → no O \n",
    "        - discrimination in the first stage, \n",
    "            - which should establish \n",
    "                - A as a predictor of the outcome and \n",
    "                - B as an inhibitor of that outcome \n",
    "                    - which counteracts A’s influence. \n",
    "    - Then, participants learn that \n",
    "        - B by itself also predicts the outcome (B → O), and \n",
    "    - finally retention of the original discrimination between A and AB is tested. \n",
    "    - Unique cue theories, as we shall see, predict a dramatic influence of the B → O trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To provide adequate controls, \n",
    "    - the full design needed to be slightly more complex (see Table 2.1).\n",
    "    - The critical trial types in the first stage of the experimental condition were intermixed \n",
    "        - A → $O_{1}$, \n",
    "        - AB → no O, and \n",
    "        - AC → $O_{1}$ trials. \n",
    "    - In the second stage, participants saw \n",
    "        - B → $O_{1}$ trials, \n",
    "    - and then in the test phase \n",
    "        - they were presented with \n",
    "            - A, \n",
    "            - AB, and \n",
    "            - AC test stimuli. \n",
    "    - Once again, the to-be-learned items were foods or combinations of foods, and the outcomes were various allergies (or no allergy).\n",
    "* <font color=\"red\">What are the predictions about performance in the test phase?</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"blue\">Let us begin by ignoring possible unique cues.</font>\n",
    "    - In the first stage, \n",
    "        - element A should acquire a positive weight for outcome $O_{1}$,\n",
    "        - element B should acquire an equal but negative weight for the same outcome, and \n",
    "        - C should have a weight of zero. \n",
    "    - In the second phase, \n",
    "        - cue B’s negative weight will be dramatically altered, \n",
    "            - since B now predicts the outcome whereas in the first stage it was negatively associated with it. \n",
    "    - In the test, we now have \n",
    "        - one compound (AB) each of whose elements is strongly connected to $O_{1}$, and \n",
    "        - another compound (AC) consisting of an element (A) which is connected to the outcome and \n",
    "        - another element (C) which should have a weight of zero. \n",
    "* In sum, then, <font color=\"red\">participants should be more likely to predict outcome $O_{1}$ on an AB test trial than on an AC one.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/eq2.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"blue\">What are the predictions if unique cue inputs are added?</font> \n",
    "    - <font color=\"red\">Here, things are a little more complicated, but the conclusion is that participants are predicted to be at least as likely to select $O_{1}$ on an AB test trial as on an AC one.</font> \n",
    "    - The difficulty with deriving predictions arises from the indeterminacy of the relative learning rate parameters <font color=\"green\">[α in equation (3)]</font> for the elements and the unique cues, but we can explore certain boundary conditions. \n",
    "    - <font color=\"orange\">If the salience and hence learning rate for the unique cues is zero</font>,\n",
    "        - then the unique cue version reduces to the simple elemental model we have already considered. \n",
    "    - <font color=\"orange\">If the learning rate is the same for the elements and unique cues</font>,\n",
    "        - then participants should again be more likely to predict \n",
    "            - $O_{1}$ on an AB test trial \n",
    "                - than on an AC one, \n",
    "            - just as in the pure elemental model.\n",
    "    - <font color=\"orange\">Finally, if the learning rate or salience of a unique cue is much greater than that of an element</font>, then \n",
    "        - X will acquire a strong negative weight (close to −1.0) in stage 1 and \n",
    "        - B will maintain a weight close to zero. \n",
    "        - B’s weight will then increase to 1.0 in stage 2, and \n",
    "        - the ABX stimulus will have a combined weight of +1.0 in the test phase. \n",
    "        - For ACY, the weight will also be 1.0, \n",
    "            - since A’s weight is 1.0 and C and Y have weights of zero.\n",
    "        - Thus, participants are predicted to respond identically to AB and AC at test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">To summarize, on any version of an elemental or unique cue theory, participants should be at least as likely to predict outcome $O_{1}$ on the AB test trial as on the AC one.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data (real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 2.4 shows participants’ performance in each of the three phases of the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The key stage 3 data are shown in Fig. 2.4c and reveal that participants predicted O on AC trials more than on AB trials. The prediction of the model is entirely falsified.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">The problem with unique cue (and elemental) theories, it seems, is the assumption that responding to an item is determined simply by the sum of the weights of its components.</font> The fact that some of those components can be unique cues does not alter the summation assumption. What our experiment indicates is that a component of a stimulus can be radically revalued without affecting to any great degree the associative connection between that stimulus and the original category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.8.png\" width=600 />\n",
    "<img src=\"figures/cap2.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACK-PROPAGATION MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nbviewer.jupyter.org/github/psygrammer/qgm/blob/master/part3/connectionist/ch01/figures/cap1.19.png\" wdith=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">One particular type of hidden-unit network</font> has been extremely widely investigated and has been shown to have some very powerful properties.\n",
    "* In such a “<font color=\"red\">back-propagation-of-error</font>” network, the delta rule applies exactly as before, except that it is refined in order to determine how much the input-hidden weights and the hidden-output weights should be changed on a given trial. \n",
    "* The development of multi-layer networks using the generalized version of the delta rule has provided a major contribution to recent connectionist modelling, since phenomena such as the learning of <font color=\"red\">nonlinear classifications</font>, which are impossible for basic single-layer networks, can be easily dealt with by <font color=\"red\">multi-layer networks</font>.\n",
    "* Even more impressive than their ability to learn nonlinear classifications is the fact, proved by Hornik, Stinchcombe, and White (1989), that <font color=\"red\">back-propagation networks can learn essentially any mapping</font> <font color=\"blue\">between a set of input and output patterns</font> that one cares to construct. \n",
    "    - Thus, for any set of mappings from arbitrary input patterns to arbitrary output patterns (I1 → O1, I2 → O2, I3 → O3, . . .), a back-propagation network with <font color=\"red\">sufficient hidden units</font> will construct a set of weights to learn the mapping to <font color=\"red\">any desired degree of approximation</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, there is <font color=\"red\">no question about the power</font> of this sort of connectionist network for learning associative relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the question remains, <font color=\"red\">does it learn in the same way as humans?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### child language acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is undoubtedly evidence of persuasive <font color=\"red\">correspondences between human behaviour and the predictions of back-propagation networks</font>. \n",
    "* Some of the best evidence concerns child language acquisition, where it is possible to provide a network with approximately the same sort of input that children receive and to see whether characteristics of the network’s learning match those seen in children.\n",
    "    - One much-debated example concerns the learning of the past tense in English.\n",
    "        - walk–walked (regular)\n",
    "        - go–went, send–sent, have–had, etc. (irregular)\n",
    "        - “over-regularize” irregular verbs:\n",
    "            - human : “goed”, “sended”\n",
    "            - It turns out that back-propagation networks are also able to produce such errors (Plunkett & Marchman, 1993)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### human associative learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the more general perspective of human associative learning, however, the <font color=\"red\">basic back-propagation system is inadequate</font>, and the reason is simple: \n",
    "    - As McCloskey and Cohen (1989) showed, such <font color=\"red\">networks predict catastrophic interference</font> just like unique cue and elemental models.\n",
    "        - To illustrate, we ran a simple back-propagation simulation of the experimental condition in Table 2.1. \n",
    "            - There were three input units, corresponding to stimuli \n",
    "                - A, \n",
    "                - B, and \n",
    "                - C, and \n",
    "            - one output unit corresponding to the target outcome \n",
    "                - O1. \n",
    "            - In the first stage, \n",
    "                - A → O1, \n",
    "                - AB → no O, and \n",
    "                - AC → O1 \n",
    "                - trials were presented repeatedly until correct responding was observed. \n",
    "            - In the second stage, \n",
    "                - B → O1 \n",
    "                - trials were presented and again, \n",
    "                - training continued until the correct output was obtained. \n",
    "            - Finally, stimuli \n",
    "                - AB and \n",
    "                - AC \n",
    "                - were presented in the test phase. \n",
    "         - <font color=\"red\">In contradiction to the results illustrated in Fig. 2.4</font>, \n",
    "             - <font color=\"red\">AB evoked a stronger O1 response than AC</font>. \n",
    "        - We have tried many permutations of the network architecture and training regime but have been unable to find any circumstances in which this outcome is reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.8.png\" width=600 />\n",
    "<img src=\"figures/cap2.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The problem for back-propagation models</font> is particularly starkly illustrated in an experiment and accompanying simulation conducted by López, Shanks, Almaraz, and Fernández (1998). This study again used a simple prediction task, but in this case the cues were symptoms and the outcomes diseases. The design is shown in Table 2.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Participants received information about \n",
    "    - the symptoms that a particular patient presented and \n",
    "    - they had to diagnose the disease this patient was suffering from.\n",
    "* Table 2.2 shows that across \n",
    "    - stages 1 and 2 \n",
    "    - the cues of interest, \n",
    "        - A and D, \n",
    "    - were followed by their respective outcomes, \n",
    "        - $O_{1}$ and $O_{2}$, \n",
    "    - exactly the same number of times and \n",
    "    - in compound with cues that had undergone exactly the same treatment. \n",
    "    - The only difference between A and D was that \n",
    "        - A was a better predictor of $O_{1}$ than \n",
    "            - its pairmate B in stage 1 and \n",
    "        - a worse predictor than \n",
    "            - its pairmate C in stage 2, \n",
    "        - whereas for D, this was reversed. \n",
    "    - That is, D was \n",
    "        - a worse predictor of $O_{2}$ than \n",
    "            - E in stage 1 and \n",
    "        - a better predictor than \n",
    "            - F in stage 2. \n",
    "    - The various trial types in each stage were randomly intermixed. \n",
    "* The critical component of the design is that, just as in the Shanks et al. (1998a) experiment shown in Table 2.1, the stage 2 contingencies indirectly contradict the ones presented in stage 1, in as much as <font color=\"red\">stage 1 tends to suggest that A is a powerful predictor</font> of the disease and that <font color=\"red\">D prevents the disease</font>, while <font color=\"blue\">stage 2 tends to suggest the exact opposite</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Participants learned to predict the correct outcomes during both stages 1 and 2. In the subsequent test stage, trials of each type from the two stages were re-presented without any feedback.\n",
    "* <font color=\"red\">The key issue is whether participants could remember the correct responses for the stage 1 trial types</font>.\n",
    "    - If they have forgotten or unlearned the stage 1 trial types, they will obviously make many errors on test trials from stage 1. \n",
    "    - In fact the data, reported in Table 2.2 (bold figures), reveal good recall of the stage 1 contingencies. \n",
    "        - Participants tended to predict the target disease on AB and E trials and predicted no disease on B and DE trials, consistent with the phase 1 associations.\n",
    "* We then conducted a series of <font color=\"red\">simulations using back-propagation networks</font>, as described in McClelland and Rumelhart (1988). \n",
    "    - Different parameters and network architectures (different numbers of hidden units) were tested in these simulations, but all of them showed the basic <font color=\"red\">catastrophic forgetting effect</font>, thus only the details of one of them will be described.\n",
    "    - The outcome of this simulation is presented in Fig. 2.5. \n",
    "        - A three-layered network was used, \n",
    "            - consisting of \n",
    "                - six input units, \n",
    "                    - corresponding to the six cues (symptoms), \n",
    "                - 10 hidden units \n",
    "                    - to allow an internal representation of the input information to be formed, and \n",
    "                - two output units \n",
    "                    - corresponding to the two outcomes (diseases) used in the training stage.\n",
    "                    - “No disease” was coded as an output of zero on both output units.\n",
    "        - This pattern of results shows that, <font color=\"red\">unlike the participants in the experiment</font>, the network performed during the test stage according to the contingencies it had learned during Block 2 of the learning stage and had <font color=\"red\">catastrophically forgotten the relationships programmed during Block 1</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.11.png\" width=600 />\n",
    "<img src=\"figures/cap2.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Yet another problem with back-propagation networks</font> <font color=\"blue\">as models of human associative learning</font> is that they do not always appear to generalize in an appropriate manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As an illustration, suppose that \n",
    "    - one classification problem consists of \n",
    "        - A → O and \n",
    "        - AB → no O trials, \n",
    "        - while a second consists of \n",
    "            - AC → O and \n",
    "            - ABC → no O trials. \n",
    "    - These problems are identical except that both trial types in the second problem have an added element, C. \n",
    "* Just as in the experiment described earlier (Fig. 2.3), intuition suggests that adding such an element makes the <font color=\"red\">trial types more similar</font> and therefore must make the <font color=\"red\">classification harder to learn</font>, a prediction that has been <font color=\"red\">confirmed empirically in an animal discrimination learning study</font> by Pearce and Redhead (1993). However, Pearce (1994) showed that <font color=\"blue\">back-propagation networks are unable to reproduce this effect</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURAL MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results we have reported carry a straightforward message: \n",
    "* <font color=\"red\">Representations of complex stimuli</font> need to be bound quite <font color=\"red\">tightly together</font> in such a way that learning <font color=\"red\">something new</font> about one of the elements of a stimulus does not strongly transfer back to the stimulus itself. \n",
    "* In other words, <font color=\"red\">stimuli need to be coded in a configural rather than an elemental manner</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">The basic idea</font> behind configural networks \n",
    "* is illustrated in Fig. 2.6. \n",
    "* When a stimulus is presented, \n",
    "    - it is <font color=\"red\">coded</font> via \n",
    "        - the <font color=\"red\">direct activation</font> of \n",
    "        - a <font color=\"red\">unique hidden unit</font> \n",
    "            - dedicated to <font color=\"red\">that stimulus</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, as it stands, this model would be inadequate, \n",
    "* since it <font color=\"red\">does not allow any degree of generalization</font>, \n",
    "* so it needs to be supplemented with the idea that a hidden unit dedicated to a given stimulus can be activated by another stimulus to the extent that the two are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models \n",
    "* Modles based on these design characteristics have been explored by Pearce (1987, 1994, 2002) and Kruschke (1992, 1993). \n",
    "    - Although they differ in their details, each <font color=\"red\">provides approximately the correct trade-off between generalization and protection from interference</font>.\n",
    "* Pearce’s (1994) configural model\n",
    "    - Let us consider how Pearce’s (1994) configural model can predict the <font color=\"red\">absence of catastrophic forgetting</font>.\n",
    "    - The model has been implemented \n",
    "        - as a connectionist network that includes \n",
    "            - four layers of units: \n",
    "                - an input layer, \n",
    "                - two layers of hidden units \n",
    "                    - (an output layer and \n",
    "                    - a layer of configural units) and \n",
    "                - a single-unit layer that \n",
    "                    - represents the outcome. \n",
    "        - The activation level of this outcome unit \n",
    "            - determines the system response. \n",
    "        - The units in the input layer \n",
    "            - can be at an activation level of either \n",
    "                - 0 or \n",
    "                - 1, \n",
    "            - depending on whether the element of the stimulus pattern the unit is representing is \n",
    "                - absent or \n",
    "                - present, respectively. \n",
    "        - Each input unit is connected to a single output unit. \n",
    "        - The intervention of these output units ensures that each stimulus pattern <font color=\"red\">activates maximally</font> (an activation level of 1) a <font color=\"red\">single configural unit</font>.\n",
    "            - Henceforth, the <font color=\"blue\">configural unit can be regarded as representing a particular stimulus pattern</font>.\n",
    "    - <font color=\"red\">If we assume that configural unit x becomes maximally activated when input pattern X is presented, what will be its activation value when input pattern Y is presented?</font> \n",
    "        - According to the model, the activation value $a_{x}$ of configural unit x will be proportional to the degree of similarity between the stimulus patterns.\n",
    "        - Pearce (1987, 1994) assumes that the <font color=\"red\">similarity of input patterns X and Y is a linear function of the number of elements they share</font> :\n",
    "        <img src=\"figures/cap2.14.png\" width=600 />\n",
    "            - where \n",
    "                - $n_{C}$ is the number of input units both patterns share and \n",
    "                - $n_{X}$ and $n_{Y}$ are the number of input units that are specific to each stimulus pattern.\n",
    "        - <font color=\"red\">Thus, the activation level of the outcome unit when pattern X is presented ($V_{x}$) has a double origin</font>. \n",
    "            - Part of the activation is conveyed \n",
    "                - by the <font color=\"blue\">connection between</font> \n",
    "                    - the <font color=\"blue\">configural unit maximally activated</font> and \n",
    "                    - the <font color=\"blue\">outcome unit ($w_{x}$),</font> and\n",
    "            - some of its activation \n",
    "                - comes through the <font color=\"green\">connections between</font> \n",
    "                    - <font color=\"green\">other configural units activated</font> \n",
    "            - through generalization and the outcome unit:\n",
    "                <img src=\"figures/cap2.15.png\" width=600 />\n",
    "                - where \n",
    "                    - $S_{x,i}$ is the squared activation of these other configural units [see equation (4)] and \n",
    "                    - $w_{i}$ represents their connections to the outcome unit.\n",
    "    - <font color=\"red\">Associative learning involves modifications only in</font> \n",
    "        - the <font color=\"red\">weight of the connection between</font> \n",
    "            - the <font color=\"blue\">configural unit maximally activated</font> (one for each stimulus pattern) and \n",
    "            - the <font color=\"blue\">outcome unit</font>. \n",
    "        - These modifications are governed by equation (6):\n",
    "            <img src=\"figures/cap2.16.png\" width=600 />\n",
    "            - Note the similarity between equations (3) and (6). \n",
    "            - As in the Rescorla–Wagner model, the modification of weights is proportional to \n",
    "                - an error term, \n",
    "                - $α$ represents the learning rate, and \n",
    "                - $t$ is set \n",
    "                    - to 1 \n",
    "                        - when the outcome is present and \n",
    "                    - to 0 \n",
    "                        - otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resutls (Pearce’s configural model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pearce’s model is able to account for a good deal of the data reviewed in this chapter thus far. \n",
    "    - Because stimuli are represented configurally, \n",
    "        - the model’s predictions are unaffected by whether or not a particular classification is linear, and \n",
    "        - hence it can predict the learnability of the feature-neutral discrimination shown in Fig. 2.2.\n",
    "            <img src=\"figures/cap2.10.png\" width=600 />\n",
    "        - Also, the theory predicts the faster learning for A than for AB shown in Fig. 2.3, \n",
    "            - since there is less generalization between A and ABC than between AB and ABC\n",
    "            <img src=\"figures/cap2.6.png\" width=600 />\n",
    "        - Finally, it accounts, at least partially (see Shanks et al., 1998a) for the data in Fig. 2.4, as Wilson and Pearce (1992) have shown formally.\n",
    "        <img src=\"figures/cap2.8.png\" width=600 />\n",
    "        <img src=\"figures/cap2.9.png\" width=600 />\n",
    "* To conclude, Pearce’s configural model allows us to give \n",
    "    - a degree of coherence to the pattern of results described so far.\n",
    "    - The <font color=\"red\">absence of catastrophic forgetting</font> can be understood in terms of the model. \n",
    "    - It provides a solution to the catastrophic forgetting problem, \n",
    "        - which involves a <font color=\"red\">trade-off between two empirical constraints</font>, namely, the fact that <font color=\"blue\">new information does not cause complete unlearning of prior knowledge</font> and the <font color=\"green\">ability to adapt to the new incoming information through a process of generalization</font>. \n",
    "    - This particular solution is based on the creation of <font color=\"red\">semi-distributed representations of the incoming information</font> <font color=\"blue\">by means of the assignment of exclusive configural representations</font> to each new input pattern and the operation of a generalization mechanism based on pattern similarity. \n",
    "    - By <font color=\"red\">abandoning the notion that stimuli are coded elementally</font>, findings that are problematic for single-layer networks can be encompassed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPRESENTATIONAL FLEXIBILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it would be nice to end the chapter with the conclusion that connectionist models incorporating some form of configural coding scheme provide powerful models of basic human learning processes. <font color=\"blue\">However, such models turns out to be lacking an absolutely key capacity, namely</font> <font color=\"red\">representational flexibility</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### blocking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고\n",
    "* [5] 차례 Blocking - Kamin, 1969 - http://m.blog.naver.com/khrireg/10185382717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Williams et al. used an adaptation of the classic two- stage “blocking” design of Kamin (1968)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Williams et al. (1994, Experiment 4) conducted a blocking experiment such as this, but pretrained various groups of participants in different ways.\n",
    "* In one condition the pretraining was designed to foster an “elemental” strategy, \n",
    "* whereby participants would to some degree analyse each cue separately.\n",
    "* we might expect to see that cue A is blocked and receives lower ratings than cue C, and this is exactly what happened for participants who received the elemental pretrain- ing. However, for those participants given the configural pretraining, no blocking was observed, and instead A and C received equal ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* However, in this experiment there were two modifications which we, following Williams (1995), thought might encourage a <font color=\"red\">greater degree of elemental processing</font>. \n",
    "* First, in an initial training stage (stage 1), only the elements were presented, so participants’ initiation should have suggested to them that the task had an elemental nature.\n",
    "* Second, during the stage in which the A → O/AB → no O discrimination was learned, participants also saw B → no O trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.19.png\" width=600 />\n",
    "<img src=\"figures/cap2.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.8.png\" width=600 />\n",
    "<img src=\"figures/cap2.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pair of results given in Fig. 2.4 and 2.7 confirms Williams et al.’s conjecture that the representation of a compound stimulus AB can be <font color=\"red\">flexibly altered</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the meantime, however, what we can say is that <font color=\"red\">current connectionist models are missing an important feature</font> in their inability to accommodate representational flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROLE OF THE HIPPOCAMPUS IN STIMULUS CODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2e/Gray739-emphasizing-hippocampus.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Efforts to develop connectionist models of associative learning have commonly been informed by <font color=\"red\">neuropsychological considerations</font>, so in this section I briefly review the evidence concerning the neural substrates of learning.\n",
    "* paired-associate learning, which requires participants to learn arbitrary associations between word pairs, and which therefore resembles the sorts of tasks used in the experiments described here, is normally included in test batteries for detecting amnesia.\n",
    "* Despite this consensus, many researchers believe that the hippocampus does <font color=\"red\">not contribute to all associative learning tasks</font> and that <font color=\"blue\">instead its involvement is restricted to declarative memory tasks</font>, in which successful performance requires conscious retrieval of facts or episodes.\n",
    "* The claim that amnesia is restricted to declarative memory deficits is <font color=\"red\">controversial</font>, however, for two reasons. \n",
    "* Thus, it is possible that the <font color=\"red\">hippocampus is involved</font> in, and indeed is necessary for normal performance in, <font color=\"red\">essentially all forms of associative learning task</font>.\n",
    "* Putting that issue to one side, a more subtle and germane claim is that the hippocampus is particularly involved in tasks that require the <font color=\"red\">formation of configural representations</font>.\n",
    "* The <font color=\"red\">hippocampal-configural theory</font> of Sutherland and Rudy is particularly attractive, not only because it grounds the elemental/configural distinction on an underlying neural substrate but also because it <font color=\"red\">hints that the representational flexibility</font> described in the previous section may be <font color=\"red\">attributable to differential loading of tasks on hippocampal function</font>.\n",
    "* <font color=\"red\">Unfortunately, though, other evidence has failed to support the theory</font>. Perhaps most clear-cut is evidence (Gallagher & Holland, 1992) that hippocampal lesions do not impair acquisition of the feature-neutral discrimination (see Fig. 2.2) and also evidence that human amnesic patients are no more impaired on the transverse patterning task than on a linear discrimination of equivalent difficulty (Reed & Squire, 1999).2 It has been confirmed, on the other hand, that negative patterning is impaired (McDonald et al., 1997). Overall, therefore, it does not appear that the hippocampal-configural theory, as stated in its original form, is adequate.\n",
    "* Rudy & Sutherland (1995) have argued persuasively that this approach can account for much of the appar- ently conflicting evidence on the effects of hippocampal lesions, and O’Reilly & Rudy (2001) have extended it further by suggesting that the hippocampal gain process is particularly critical in situations that require the rapid forma- tion of conjunctive representations. The details of how this proposal may be turned into an explicit computational model are beyond the scope of this chapter, but recent efforts (Gluck & Myers, 1997; O’Reilly & Rudy, 2001; Schmajuk & DiCarla, 1992) hold out considerable promise of integrating a wide range of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"localist\" and \"distributed”\n",
    "* superposition and equipotentiality.\n",
    "* similarity-based and rule-based behaviour, \n",
    "    - or (in other terminology) between “implicit” and “explicit” behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] Connectionist Models in Cognitive Psycholgy - http://www.amazon.com/Connectionist-Cognitive-Psychology-Studies-Cognition/dp/0415646901/\n",
    "* [2] Behavior Models - http://www.slideshare.net/zennboy/class-feb-15\n",
    "* [3] 레스콜라-와그너 모델(위키피디아) -  https://ko.wikipedia.org/wiki/%EA%B3%A0%EC%A0%84%EC%A0%81_%EC%A1%B0%EA%B1%B4%ED%99%94%EC%9D%98_%ED%96%89%EB%8F%99%EC%A0%81_%EC%97%B0%EA%B5%AC#.EB.A0.88.EC.8A.A4.EC.BD.9C.EB.9D.BC-.EC.99.80.EA.B7.B8.EB.84.88_.EB.AA.A8.EB.8D.B8\n",
    "* [4] 레스콜라-바그너 모델(블로그) - http://m.blog.naver.com/khrireg/10187749924\n",
    "* [5] 차례 Blocking - Kamin, 1969 - http://m.blog.naver.com/khrireg/10185382717"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
